#!/usr/bin/env python
"""
å¼‚æ­¥æ¨ç†å®¢æˆ·ç«¯ï¼šå°† GROOT policy ä¸ GrabBoxMpcEnv ç»“åˆè¿›è¡Œå¼‚æ­¥æ¨ç†

è¿™ä¸ªè„šæœ¬å®ç°äº†å¼‚æ­¥æ¨ç†æ¶æ„ï¼Œå°†æ¨ç†ä»»åŠ¡åˆ†ç¦»åˆ°æœåŠ¡å™¨ç«¯ï¼Œå®¢æˆ·ç«¯ä¸“æ³¨äº
è§‚æµ‹è·å–å’ŒåŠ¨ä½œæ‰§è¡Œï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½ã€‚

æ¶æ„ï¼š
- æœåŠ¡å™¨ç«¯ (policy_server.py): è¿è¡Œæ¨¡å‹æ¨ç†ï¼Œè¿”å›åŠ¨ä½œå—
- å®¢æˆ·ç«¯ (æœ¬è„šæœ¬): å‘é€è§‚æµ‹ï¼Œæ¥æ”¶åŠ¨ä½œï¼Œæ‰§è¡Œæ§åˆ¶

ä½¿ç”¨æ–¹æ³•ï¼š
1. å¯åŠ¨æœåŠ¡å™¨ï¼š
   python -m lerobot.async_inference.policy_server \
       --host=127.0.0.1 \
       --port=8080 \
       --fps=10 \
       --inference_latency=0.033

2. è¿è¡Œå®¢æˆ·ç«¯ï¼ˆæœ¬è„šæœ¬ï¼‰ï¼š
    python eval/eval_offline_async.py \
        --server_address=127.0.0.1:8080 \
        --ckpt_path=/path/to/checkpoint \
        --action_chunk_size=16 \
        --lerobot_dataset_path=/path/to/dataset \
        --task_description="Depalletize the box" 
        --fps=10 \
        --chunk_size_threshold=0.5
"""

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import time
from collections.abc import Callable
import threading
import pickle
from queue import Queue, Empty
from collections import deque
from typing import Optional
import argparse

import numpy as np
import torch
import grpc
import rospy

from kuavo_env.kuavo_depalletize_env import GrabBoxMpcEnv
# from viz.visualizer import RerunVisualizer
from configs.config import topic_info, \
    get_camera_observation_key, get_camera_names, \
    TASK_DATA_MODE, CAMERA_COMPONENTS, ACTION_COMPONENTS, ROBOT_VERSION, STATE_COMPONENTS
from lerobot.policies.groot.modeling_groot import GrootPolicy
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from pathlib import Path

from lerobot.transport import (
    services_pb2,  # type: ignore
    services_pb2_grpc,  # type: ignore
)
from lerobot.transport.utils import grpc_channel_options, send_bytes_in_chunks, receive_bytes_in_chunks
from lerobot.async_inference.helpers import (
    TimedObservation,
    TimedAction,
    RawObservation,
    RemotePolicyConfig,
    get_logger,
)

from kuavo_humanoid_sdk.kuavo_strategy_pytree.common.robot_sdk import RobotSDK

# å¯¼å…¥å¿…è¦çš„å·¥å…·å‡½æ•°
from eval import (
    resample_chunk_with_claw_hold,
    apply_lowpass_transition,
    publish_joint_positions,
    final_reset_arm,
)

from tqdm import tqdm

MODEL_ACTION_DT = 0.1  # seconds between predicted actions during training
MODEL_ACTION_FREQUENCY = 1.0 / MODEL_ACTION_DT
TARGET_CONTROL_FREQUENCY = 100.0
TARGET_CONTROL_DT = 1.0 / TARGET_CONTROL_FREQUENCY
CHUNK_TRANSITION_DURATION_S = 0.2  # seconds of low-pass smoothing at chunk boundary
LOWPASS_ALPHA = 0.85  # closer to 1 => smoother (slower) transitions
ENABLE_CHUNK_TRANSITION_LOWPASS = True

logger = get_logger("groot_async_client")

AGGREGATE_FUNCTIONS = {
    "weighted_average": lambda old, new: 0.3 * old + 0.7 * new,
    "latest_only": lambda old, new: new,
    "average": lambda old, new: 0.5 * old + 0.5 * new,
    "conservative": lambda old, new: 0.7 * old + 0.3 * new,
}


def get_aggregate_function(name: str) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:
    """Get aggregate function by name from registry."""
    if name not in AGGREGATE_FUNCTIONS:
        available = list(AGGREGATE_FUNCTIONS.keys())
        raise ValueError(f"Unknown aggregate function '{name}'. Available: {available}")
    return AGGREGATE_FUNCTIONS[name]

class GrootAsyncClient:
    """å¼‚æ­¥æ¨ç†å®¢æˆ·ç«¯ï¼Œé€‚é… GrabBoxMpcEnv å’Œ GROOT policy"""
    
    def __init__(
        self,
        server_address: str,
        ckpt_path: str,
        action_chunk_size: int = 20,
        lerobot_dataset_path: Optional[str] = None,
        task_description: str = "Depalletize the box",
        control_arm: bool = True,
        control_claw: bool = True,
        fps: float = 30.0,
        chunk_size_threshold: float = 0.5,
        rotate_head_camera: bool = False,
    ):
        """
        Args:
            server_address: gRPC æœåŠ¡å™¨åœ°å€ (æ ¼å¼: "host:port")
            ckpt_path: GROOT æ¨¡å‹ checkpoint è·¯å¾„
            action_chunk_size: åŠ¨ä½œå—å¤§å°
            lerobot_dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç”¨äºåŠ è½½ç»Ÿè®¡ä¿¡æ¯ï¼‰
            task_description: ä»»åŠ¡æè¿°
            control_arm: æ˜¯å¦æ§åˆ¶æ‰‹è‡‚
            control_claw: æ˜¯å¦æ§åˆ¶å¤¹çˆª
            fps: æ§åˆ¶é¢‘ç‡
            chunk_size_threshold: åŠ¨ä½œé˜Ÿåˆ—é˜ˆå€¼ï¼ˆå½“é˜Ÿåˆ—å¤§å°/åŠ¨ä½œå—å¤§å° < threshold æ—¶å‘é€æ–°è§‚æµ‹ï¼‰
            rotate_head_camera: æ˜¯å¦æ—‹è½¬å¤´éƒ¨ç›¸æœºå›¾åƒ180åº¦
        """
        self.server_address = server_address
        self.ckpt_path = ckpt_path
        self.action_chunk_size = action_chunk_size
        self.task_description = task_description
        self.control_arm = control_arm
        self.control_claw = control_claw
        self.fps = fps
        self.environment_dt = 1.0 / fps
        self.chunk_size_threshold = chunk_size_threshold
        self.rotate_head_camera = rotate_head_camera
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        rospy.loginfo("Initializing GrabBoxMpcEnv...")
        self.robot_sdk = RobotSDK()
        self.env = GrabBoxMpcEnv()
        # self.env.obs_buffer.wait_buffer_ready()
        time.sleep(1)
        rospy.loginfo("Environment ready")
        
        # åŠ è½½æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºç‰¹å¾æ˜ å°„ï¼‰
        self.dataset_stats = None
        self.lerobot_dataset_path = lerobot_dataset_path
        self.lerobot_features = self._load_dataset_and_get_features(lerobot_dataset_path)
        
        # è¿æ¥ gRPC æœåŠ¡å™¨
        rospy.loginfo(f"Connecting to policy server at {server_address}...")
        self.channel = grpc.insecure_channel(
            server_address, 
            grpc_channel_options(initial_backoff=f"{self.environment_dt:.4f}s")
        )
        self.stub = services_pb2_grpc.AsyncInferenceStub(self.channel)
        
        # å‘é€ Ready ä¿¡å·
        try:
            self.stub.Ready(services_pb2.Empty())
            rospy.loginfo("Connected to policy server")
        except grpc.RpcError as e:
            logger.error(f"Failed to connect to server: {e}")
            raise
        
        # å‘é€ç­–ç•¥é…ç½®
        policy_config = RemotePolicyConfig(
            policy_type="groot",
            pretrained_name_or_path=ckpt_path,
            lerobot_features=self.lerobot_features,
            actions_per_chunk=action_chunk_size,
            device="cuda:0",
            dataset_stats=self.dataset_stats,
        )
        policy_config_bytes = pickle.dumps(policy_config)
        policy_setup = services_pb2.PolicySetup(data=policy_config_bytes)
        self.stub.SendPolicyInstructions(policy_setup)
        rospy.loginfo("Policy configuration sent to server")
        
        # åŠ¨ä½œé˜Ÿåˆ—å’ŒåŒæ­¥
        self.action_queue = Queue()
        self.action_queue_lock = threading.Lock()
        self.latest_action = -1
        self.latest_action_lock = threading.Lock()
        self.action_chunk_size_received = action_chunk_size
        self.aggregate_fn = get_aggregate_function("weighted_average")
        
        # çº¿ç¨‹æ§åˆ¶
        self.shutdown_event = threading.Event()
        self.must_go = threading.Event()
        self.must_go.set()  # åˆå§‹è®¾ç½®ä¸ºå¯å‘é€è§‚æµ‹
        
        rospy.loginfo("GrootAsyncClient initialized")
    
    def _load_dataset_and_get_features(self, lerobot_dataset_path: Optional[str]) -> dict[str, dict]:
        """åŠ è½½æ•°æ®é›†å¹¶è·å–ç‰¹å¾æ˜ å°„ï¼ˆç”¨äºæœåŠ¡å™¨ç«¯è½¬æ¢ï¼‰
        
        è¿”å›æ ¼å¼: dict[str, dict] - LeRobot æ•°æ®é›†ç‰¹å¾æ ¼å¼ï¼ˆå¸¦ "observation." å‰ç¼€ï¼‰
        è¿™ä¸ªæ ¼å¼ä¼šè¢«æœåŠ¡å™¨ç«¯ç”¨äºå°† RawObservation è½¬æ¢ä¸º LeRobot æ ¼å¼
        
        æ³¨æ„ï¼šbuild_dataset_frame æœŸæœ›ï¼š
        - ds_features: æ•°æ®é›†ç‰¹å¾æ ¼å¼ï¼ˆå¦‚ "observation.state", "observation.images.image"ï¼‰
        - values: ç¡¬ä»¶ç‰¹å¾å€¼ï¼ˆå¦‚ {"state": tensor, "image": tensor}ï¼‰
        - é€šè¿‡ ds_features ä¸­çš„ "names" å­—æ®µå°† values ä¸­çš„é”®æ˜ å°„åˆ°æ•°æ®é›†ç‰¹å¾
        """
        if not lerobot_dataset_path:
            # ä½¿ç”¨é»˜è®¤è·¯å¾„
            lerobot_dataset_path = '/home/wuzr/il/kuavo-manip/benchmark/5w_four_box_random'
        
        try:
            # åŠ è½½æ•°æ®é›†ä»¥è·å–ç‰¹å¾å®šä¹‰
            dataset = LeRobotDataset(repo_id=0, root=lerobot_dataset_path)
            self.dataset_stats = dataset.meta.stats if hasattr(dataset.meta, 'stats') else None
            
            # ä»æ•°æ®é›†è·å–ç‰¹å¾å®šä¹‰ï¼ˆLeRobot æ ¼å¼ï¼Œå¸¦ "observation." å‰ç¼€ï¼‰
            # dataset.meta.features åŒ…å«å®Œæ•´çš„æ•°æ®é›†ç‰¹å¾å®šä¹‰
            if hasattr(dataset.meta, 'features') and dataset.meta.features:
                # åªä¿ç•™ observation ç›¸å…³çš„ç‰¹å¾
                lerobot_features = {
                    k: v for k, v in dataset.meta.features.items() 
                    if k.startswith("observation.")
                }
                
                # é‡è¦ï¼šå¦‚æœçŠ¶æ€ç‰¹å¾çš„ names å­—æ®µå­˜åœ¨ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å®ƒä»¬ä½¿ç”¨æ ‡å‡†çŠ¶æ€åç§°
                # æ•°æ®é›†å¯èƒ½ä½¿ç”¨äº†æ—§çš„å‘½åæ ¼å¼ï¼ˆå¦‚ {"motors": [...]}ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨
                from lerobot.utils.constants import OBS_STR
                state_key = f"{OBS_STR}.state"
                if state_key in lerobot_features and "names" in lerobot_features[state_key]:
                    # è·å–æ•°æ®é›†ä¸­çš„çŠ¶æ€åç§°
                    dataset_state_names_raw = lerobot_features[state_key]["names"]
                    
                    # å¤„ç† names å­—æ®µï¼šå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸ï¼ˆæ—§æ ¼å¼ï¼‰
                    if isinstance(dataset_state_names_raw, dict):
                        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ˆå¦‚ {"motors": [...]}ï¼‰ï¼Œæå–æ‰€æœ‰å€¼å¹¶æ‰å¹³åŒ–
                        dataset_state_names = []
                        for key, value_list in dataset_state_names_raw.items():
                            if isinstance(value_list, list):
                                dataset_state_names.extend(value_list)
                            else:
                                dataset_state_names.append(value_list)
                        rospy.loginfo(f"Converted dictionary format names to list: {len(dataset_state_names)} names")
                    elif isinstance(dataset_state_names_raw, list):
                        # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                        dataset_state_names = dataset_state_names_raw
                    else:
                        logger.warning(f"Unexpected names format: {type(dataset_state_names_raw)}. Using standard names.")
                        dataset_state_names = None
                    
                    # è·å–æ ‡å‡†çŠ¶æ€åç§°
                    from configs.config import get_states_names, STATE_COMPONENTS
                    state_components = STATE_COMPONENTS if STATE_COMPONENTS else ["J_q"]
                    standard_state_names = get_states_names(state_components=state_components)
                    
                    # å¦‚æœæ•°æ®é›†çš„çŠ¶æ€åç§°ä¸æ ‡å‡†åç§°ä¸åŒ¹é…ï¼Œä½¿ç”¨æ ‡å‡†åç§°æ›¿æ¢
                    # è¿™æ ·å¯ä»¥ç¡®ä¿å®¢æˆ·ç«¯å‘é€çš„é”®åä¸æœåŠ¡å™¨ç«¯æœŸæœ›çš„ä¸€è‡´
                    if dataset_state_names is None or dataset_state_names != standard_state_names:
                        if dataset_state_names is not None:
                            logger.warning(
                                f"Dataset state names ({len(dataset_state_names)} names) don't match "
                                f"standard names ({len(standard_state_names)} names). "
                                f"Using standard names for compatibility."
                            )
                            logger.debug(f"Dataset names (first 5): {dataset_state_names[:5] if len(dataset_state_names) >= 5 else dataset_state_names}")
                            logger.debug(f"Standard names (first 5): {standard_state_names[:5] if len(standard_state_names) >= 5 else standard_state_names}")
                        else:
                            rospy.loginfo(f"Using standard state names: {len(standard_state_names)} names")
                        
                        # æ›´æ–°ç‰¹å¾å®šä¹‰ä½¿ç”¨æ ‡å‡†åç§°
                        lerobot_features[state_key]["names"] = standard_state_names
                        lerobot_features[state_key]["shape"] = (len(standard_state_names),)
                    else:
                        # å³ä½¿åŒ¹é…ï¼Œä¹Ÿè¦ç¡®ä¿ names æ˜¯åˆ—è¡¨æ ¼å¼ï¼ˆä¸æ˜¯å­—å…¸ï¼‰
                        lerobot_features[state_key]["names"] = dataset_state_names
                
                rospy.loginfo(f"Loaded lerobot_features from dataset: {list(lerobot_features.keys())}")
                return lerobot_features
            
            # å¦‚æœæ•°æ®é›†æ²¡æœ‰ç‰¹å¾å®šä¹‰ï¼Œä» policy é…ç½®æ„å»º
            logger.warning("Dataset does not have features, building from policy config...")
            policy = GrootPolicy.from_pretrained(Path(self.ckpt_path), strict=False)
            
            # æ„å»ºç¡¬ä»¶ç‰¹å¾æ˜ å°„ï¼ˆç”¨äº hw_to_dataset_featuresï¼‰
            from lerobot.datasets.utils import hw_to_dataset_features
            from lerobot.utils.constants import OBS_STR
            
            hw_features = {}
            
            # æ·»åŠ çŠ¶æ€ç‰¹å¾ï¼ˆç¡¬ä»¶æ ¼å¼ï¼‰
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ ‡å‡†çŠ¶æ€åç§°å‡½æ•°
            from configs.config import get_states_names
            
            state_components = STATE_COMPONENTS if STATE_COMPONENTS else ["J_q"]
            # ä½¿ç”¨ get_states_names è·å–æ ‡å‡†çŠ¶æ€åç§°åˆ—è¡¨
            state_names = get_states_names(state_components=state_components)
            state_dim = len(state_names)
            
            # å¯¹äº hw_to_dataset_featuresï¼Œæˆ‘ä»¬éœ€è¦å°†çŠ¶æ€ä½œä¸ºå¤šä¸ªå•ç‹¬çš„ float ç‰¹å¾
            # ä½†å®é™…ä¸Šï¼Œbuild_dataset_frame æœŸæœ› state ç‰¹å¾æœ‰ names å­—æ®µ
            # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ„å»ºç‰¹å¾å®šä¹‰
            camera_names = get_camera_names(CAMERA_COMPONENTS)
            
            # æ‰‹åŠ¨æ„å»º LeRobot ç‰¹å¾æ ¼å¼
            lerobot_features = {}
            
            # æ·»åŠ çŠ¶æ€ç‰¹å¾
            lerobot_features[f"{OBS_STR}.state"] = {
                "dtype": "float32",
                "shape": (state_dim,),
                "names": state_names,
            }
            
            # å¯¼å…¥ç›¸æœºé”®åæ˜ å°„
            from configs.config import CAMERA_KEY_MAPPING
            
            # æ·»åŠ ç›¸æœºç‰¹å¾
            for camera_name in camera_names:
                # å°†ç›¸æœºåç§°æ˜ å°„ä¸ºåŸºç¡€åç§°ï¼ˆcam_head, cam_chestç­‰ï¼‰
                # æ•°æ®é›†ç‰¹å¾é”®åä½¿ç”¨åŸºç¡€åç§°ï¼šobservation.images.cam_head
                cam_base_name = CAMERA_KEY_MAPPING.get(camera_name, f"cam_{camera_name}")
                
                # ä» policy config è·å–å›¾åƒå½¢çŠ¶
                # æ³¨æ„ï¼špolicy.config.image_features ä¸­çš„é”®å¯èƒ½æ˜¯ observation.images.cam_head æ ¼å¼
                # æˆ‘ä»¬éœ€è¦æ£€æŸ¥ä¸¤ç§å¯èƒ½çš„é”®åæ ¼å¼
                img_feat = None
                if hasattr(policy.config, 'image_features'):
                    # å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ camera_nameï¼ˆå‘åå…¼å®¹ï¼‰
                    if camera_name in policy.config.image_features:
                        img_feat = policy.config.image_features[camera_name]
                    # å†å°è¯•ä½¿ç”¨ observation.images.{base_name} æ ¼å¼
                    elif f"observation.images.{cam_base_name}" in policy.config.image_features:
                        img_feat = policy.config.image_features[f"observation.images.{cam_base_name}"]
                
                if img_feat is not None:
                    # PolicyFeature.shape æ˜¯ (C, H, W)
                    h, w, c = img_feat.shape[1], img_feat.shape[2], img_feat.shape[0]
                else:
                    h, w, c = 224, 224, 3
                
                lerobot_features[f"{OBS_STR}.images.{cam_base_name}"] = {
                    "dtype": "image",
                    "shape": (h, w, c),
                    "names": ["height", "width", "channels"],
                }
            
            rospy.loginfo(f"Built lerobot_features from policy: {list(lerobot_features.keys())}")
            return lerobot_features
            
        except Exception as e:
            logger.warning(f"Could not load dataset: {e}. Using default features.")
            import traceback
            traceback.print_exc()
            # è¿”å›é»˜è®¤ç‰¹å¾æ˜ å°„ï¼ˆLeRobot æ ¼å¼ï¼‰
            from lerobot.utils.constants import OBS_STR
            return {
                f"{OBS_STR}.state": {
                    "dtype": "float32",
                    "shape": (16,),
                    "names": [f"state_{i}" for i in range(16)],
                },
                f"{OBS_STR}.images.image": {
                    "dtype": "image",
                    "shape": (224, 224, 3),
                    "names": ["height", "width", "channels"],
                },
            }
    
    def _convert_obs_to_lerobot_format(self, obs_data: dict) -> RawObservation:
        """å°† GrabBoxMpcEnv çš„è§‚æµ‹è½¬æ¢ä¸º LeRobot æ ¼å¼
        
        æ³¨æ„ï¼š
        1. build_dataset_frame æœŸæœ›çŠ¶æ€è¢«åˆ†è§£ä¸ºå•ç‹¬çš„ç»„ä»¶ï¼ˆæ ¹æ® lerobot_features ä¸­çš„ namesï¼‰
        2. å¯¹äºå›¾åƒï¼Œbuild_dataset_frame ä¼šä»é”®åå»æ‰ "observation.images." å‰ç¼€æ¥æŸ¥æ‰¾ values ä¸­çš„é”®
           ä¾‹å¦‚ï¼šç‰¹å¾é”®æ˜¯ "observation.images.cam_head"ï¼Œä¼šä» values["cam_head"] ä¸­è·å–å€¼
           æ‰€ä»¥æˆ‘ä»¬éœ€è¦å°†ç›¸æœºåç§°æ˜ å°„ä¸ºåŸºç¡€åç§°ï¼ˆcam_head, cam_chestç­‰ï¼‰
        3. çŠ¶æ€é”®åå¿…é¡»ä¸ lerobot_features ä¸­ "observation.state" çš„ "names" å­—æ®µå®Œå…¨åŒ¹é…
        """
        raw_obs = {}
        
        # å¯¼å…¥ç›¸æœºé”®åæ˜ å°„
        from configs.config import CAMERA_KEY_MAPPING
        
        # è½¬æ¢ç›¸æœºå›¾åƒ
        camera_names = get_camera_names(CAMERA_COMPONENTS)
        for camera_name in camera_names:
            if camera_name in obs_data:
                # obs_data ä¸­çš„å›¾åƒæ ¼å¼æ˜¯ (T, H, W, C)
                # è½¬æ¢ä¸º numpy å¹¶å–æœ€åä¸€å¸§
                img_np = obs_data[camera_name]
                if img_np.ndim == 4:
                    # å–æœ€åä¸€å¸§: (T, H, W, C) -> (H, W, C)
                    img_np = img_np[-1]
                # ä¿æŒä¸º numpy arrayï¼Œæ ¼å¼: (H, W, C)
                
                # å¦‚æœå¯ç”¨å¤´éƒ¨ç›¸æœºæ—‹è½¬ä¸”å½“å‰æ˜¯å¤´éƒ¨ç›¸æœºï¼ˆimageï¼‰ï¼Œåˆ™æ—‹è½¬180åº¦
                if self.rotate_head_camera and camera_name == "image":
                    # æ—‹è½¬180åº¦ï¼šä½¿ç”¨np.rot90ï¼Œk=2è¡¨ç¤ºæ—‹è½¬180åº¦ï¼Œaxes=(0,1)è¡¨ç¤ºåœ¨Hå’ŒWç»´åº¦ä¸Šæ—‹è½¬
                    # img_np shape: (H, W, C)
                    # æ³¨æ„ï¼šnp.rot90å¯èƒ½äº§ç”Ÿè´Ÿæ­¥é•¿çš„è§†å›¾ï¼Œéœ€è¦copy()æ¥åˆ›å»ºè¿ç»­æ•°ç»„
                    img_np = np.rot90(img_np, k=2, axes=(0, 1)).copy()
                
                # å°†ç›¸æœºåç§°æ˜ å°„ä¸ºåŸºç¡€åç§°ï¼ˆcam_head, cam_chestç­‰ï¼‰
                # build_dataset_frame ä¼šä» "observation.images.{base_name}" å»æ‰å‰ç¼€ï¼ŒæŸ¥æ‰¾ values[base_name]
                cam_base_name = CAMERA_KEY_MAPPING.get(camera_name, f"cam_{camera_name}")
                raw_obs[cam_base_name] = img_np.astype(np.float32) if isinstance(img_np, np.ndarray) else np.array(img_np, dtype=np.float32)
        
        # è½¬æ¢çŠ¶æ€ï¼šéœ€è¦åˆ†è§£ä¸ºå•ç‹¬ç»„ä»¶
        # é‡è¦ï¼šä½¿ç”¨ä¸ lerobot_features ä¸­å®Œå…¨ç›¸åŒçš„çŠ¶æ€åç§°åˆ—è¡¨
        if "state" in obs_data:
            state_np = obs_data["state"]
            if state_np.ndim == 2:
                # å–æœ€åä¸€å¸§: (T, D) -> (D,)
                state_np = state_np[-1]
            
            # ä» lerobot_features è·å–çŠ¶æ€åç§°åˆ—è¡¨ï¼ˆä¸æœåŠ¡å™¨ç«¯ä½¿ç”¨çš„å®Œå…¨ä¸€è‡´ï¼‰
            from lerobot.utils.constants import OBS_STR
            state_key = f"{OBS_STR}.state"
            
            if state_key in self.lerobot_features and "names" in self.lerobot_features[state_key]:
                # ä½¿ç”¨ç‰¹å¾å®šä¹‰ä¸­çš„çŠ¶æ€åç§°ï¼ˆè¿™æ˜¯æœåŠ¡å™¨ç«¯æœŸæœ›çš„ï¼‰
                state_names_raw = self.lerobot_features[state_key]["names"]
                
                # å¤„ç† names å­—æ®µï¼šå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸ï¼ˆæ—§æ ¼å¼ï¼‰
                if isinstance(state_names_raw, dict):
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ˆå¦‚ {"motors": [...]}ï¼‰ï¼Œæå–æ‰€æœ‰å€¼å¹¶æ‰å¹³åŒ–
                    state_names = []
                    for key, value_list in state_names_raw.items():
                        if isinstance(value_list, list):
                            state_names.extend(value_list)
                        else:
                            state_names.append(value_list)
                    logger.debug(f"Converted dictionary format names to list: {len(state_names)} names")
                elif isinstance(state_names_raw, list):
                    # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                    state_names = state_names_raw
                else:
                    # å¦‚æœä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯å­—å…¸ï¼Œä½¿ç”¨æ ‡å‡†åç§°
                    logger.warning(f"Unexpected names format: {type(state_names_raw)}. Using fallback.")
                    from configs.config import get_states_names
                    state_components = STATE_COMPONENTS if STATE_COMPONENTS else ["J_q"]
                    state_names = get_states_names(state_components=state_components)
            else:
                # å¦‚æœæ²¡æœ‰ç‰¹å¾å®šä¹‰ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ ‡å‡†çŠ¶æ€åç§°
                from configs.config import get_states_names
                state_components = STATE_COMPONENTS if STATE_COMPONENTS else ["J_q"]
                state_names = get_states_names(state_components=state_components)
                logger.warning("Using fallback state names from config")
            
            # å°†çŠ¶æ€ tensor åˆ†è§£ä¸ºå•ç‹¬ç»„ä»¶ï¼Œä½¿ç”¨ç‰¹å¾å®šä¹‰ä¸­çš„çŠ¶æ€åç§°
            for idx, state_name in enumerate(state_names):
                if idx < len(state_np):
                    raw_obs[state_name] = float(state_np[idx])
                else:
                    # å¦‚æœçŠ¶æ€ç»´åº¦ä¸è¶³ï¼Œä½¿ç”¨ 0.0 å¡«å……
                    logger.warning(f"State dimension mismatch: expected {len(state_names)}, got {len(state_np)}. Padding with 0.0")
                    raw_obs[state_name] = 0.0
            
            # å¦‚æœè¿˜æœ‰å‰©ä½™çš„çŠ¶æ€å€¼ï¼Œæ·»åŠ ä¸ºé€šç”¨çŠ¶æ€ç»„ä»¶ï¼ˆè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºä¿æŠ¤ï¼‰
            if len(state_np) > len(state_names):
                logger.warning(
                    f"State has more dimensions ({len(state_np)}) than expected ({len(state_names)}). "
                    f"Extra dimensions will be ignored."
                )
        
        # æ·»åŠ ä»»åŠ¡æè¿°
        raw_obs["task"] = self.task_description
        
        return raw_obs
    
    def _convert_action_to_robot_format(self, action_tensor: torch.Tensor) -> np.ndarray:
        """å°†æ¨¡å‹è¾“å‡ºçš„åŠ¨ä½œè½¬æ¢ä¸ºæœºå™¨äººæ ¼å¼
        
        æ³¨æ„ï¼šæœåŠ¡å™¨ç«¯çš„ postprocessor å·²ç»è¿›è¡Œäº†åå½’ä¸€åŒ–ï¼Œ
        æ‰€ä»¥è¿™é‡Œåªéœ€è¦è½¬æ¢ä¸º numpy array å³å¯ï¼Œä¸éœ€è¦å†æ¬¡åå½’ä¸€åŒ–
        """
        # action_tensor æ˜¯ (action_dim,) çš„ tensor
        # æœåŠ¡å™¨ç«¯å·²ç»å®Œæˆäº†åå½’ä¸€åŒ–ï¼Œç›´æ¥è½¬æ¢ä¸º numpy
        action_np = action_tensor.cpu().numpy()
        
        return action_np

    def _inspect_action_queue(self):
        with self.action_queue_lock:
            queue_size = self.action_queue.qsize()
            # timestamps = sorted([action.get_timestep() for action in self.action_queue.queue])
            timestamps = sorted([action[0] for action in self.action_queue.queue])
        rospy.loginfo(f"Queue size: {queue_size}, Queue contents: {timestamps}")
        return queue_size, timestamps
    
    def _aggregate_action_queues(
        self,
        incoming_actions: list[TimedAction],
        aggregate_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None = None,
    ):
        """Finds the same timestep actions in the queue and aggregates them using the aggregate_fn"""
        if aggregate_fn is None:
            # default aggregate function: take the latest action
            def aggregate_fn(x1, x2):
                return x2

        future_action_queue = Queue()
        with self.action_queue_lock:
            internal_queue = self.action_queue.queue

        # current_action_queue = {action.get_timestep(): action.get_action() for action in internal_queue}
        current_action_queue = {action[0]: action[1] for action in internal_queue}

        for new_action in incoming_actions:
            with self.latest_action_lock:
                latest_action = self.latest_action

            # New action is older than the latest action in the queue, skip it
            if new_action.get_timestep() <= latest_action:
                continue

            # If the new action's timestep is not in the current action queue, add it directly
            elif new_action.get_timestep() not in current_action_queue:
                action_np = self._convert_action_to_robot_format(new_action.get_action())
                future_action_queue.put((new_action.get_timestep(), action_np))
                continue

            aggregated_action = aggregate_fn(
                current_action_queue[new_action.get_timestep()], new_action.get_action().cpu().numpy()
            )
            
            future_action_queue.put((new_action.get_timestep(), aggregated_action))

        with self.action_queue_lock:
            self.action_queue = future_action_queue
    
    def receive_actions(self):
        """æ¥æ”¶åŠ¨ä½œçº¿ç¨‹"""
        rospy.loginfo("Action receiving thread started")
        
        while not self.shutdown_event.is_set():
            try:
                # ä»æœåŠ¡å™¨è·å–åŠ¨ä½œå—
                actions_chunk = self.stub.GetActions(services_pb2.Empty())
                if len(actions_chunk.data) == 0:
                    continue

                receive_time = time.time()
                
                deserialize_start = time.perf_counter()
                timed_actions = pickle.loads(actions_chunk.data)
                deserialize_time = time.perf_counter() - deserialize_start

                self.action_chunk_size_received = max(
                    self.action_chunk_size_received, 
                    len(timed_actions)
                )

                if len(timed_actions) > 0:
                    with self.latest_action_lock:
                        latest_action = self.latest_action
                
                    rospy.loginfo(f"Current latest action: {latest_action}")


                    old_size, old_timesteps = self._inspect_action_queue()
                    if not old_timesteps:
                        old_timesteps = [latest_action]

                    incoming_timesteps = [a.get_timestep() for a in timed_actions]

                    first_action_timestep = timed_actions[0].get_timestep()
                    server_to_client_latency = (receive_time - timed_actions[0].get_timestamp()) * 1000

                    rospy.loginfo(
                        f"Received action chunk for step #{first_action_timestep} | "
                        f"Latest action: #{latest_action} | "
                        f"Incoming actions: {incoming_timesteps[0]}:{incoming_timesteps[-1]} | "
                        f"Network latency (server->client): {server_to_client_latency:.2f}ms | "
                        f"Deserialization time: {deserialize_time * 1000:.2f}ms"
                    )

                start_time = time.perf_counter()
                self._aggregate_action_queues(timed_actions, self.aggregate_fn)
                queue_update_time = time.perf_counter() - start_time

                self.must_go.set()

                # Get queue state after changes
                new_size, new_timesteps = self._inspect_action_queue()

                with self.latest_action_lock:
                    latest_action = self.latest_action

                rospy.loginfo(
                    f"Latest action: {latest_action} | "
                    f"Old action steps: {old_timesteps[0]}:{old_timesteps[-1]} | "
                    f"Incoming action steps: {incoming_timesteps[0]}:{incoming_timesteps[-1]} | "
                    # f"Updated action steps: {new_timesteps[0]}:{new_timesteps[-1]}"
                    f"Updated action steps: {new_timesteps}"
                )
                rospy.loginfo(
                    f"Queue update complete ({queue_update_time:.6f}s) | "
                    f"Before: {old_size} items | "
                    f"After: {new_size} items | "
                )

            except grpc.RpcError as e:
                rospy.logerr(f"Error receiving actions: {e}")

    def _ready_to_send_observation(self, resampled_action_queue: deque) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€æ–°è§‚æµ‹"""
        with self.action_queue_lock:
            queue_size = self.action_queue.qsize()
            executed_size = len(resampled_action_queue)
            # threshold = self.action_chunk_size_received * 10 * self.chunk_size_threshold
            threshold = 100
            return (queue_size < self.action_chunk_size_received) and (executed_size == threshold or executed_size == 0)
    
    def send_observation(self, obs_buffer: deque, resampled_action_queue: deque) -> bool:
        """å‘é€è§‚æµ‹åˆ°æœåŠ¡å™¨"""
        if not self._ready_to_send_observation(resampled_action_queue):
            return False
        
        # æ£€æŸ¥ must_go æ ‡å¿—
        with self.action_queue_lock:
            queue_empty = self.action_queue.empty() and len(obs_buffer) == 0

        if not self.must_go.is_set():
            return False
        
        try:
            if len(obs_buffer) != 0:
                raw_obs = self._convert_obs_to_lerobot_format(obs_buffer.popleft())
            else:
                raw_obs = {}
            for _ in range(8):
                if len(obs_buffer) != 0:
                    obs_buffer.popleft()
                else:
                    break
            
            # åˆ›å»º TimedObservation
            with self.latest_action_lock:
                timestep = max(self.latest_action, 0)
            
            timed_obs = TimedObservation(
                timestamp=time.time(),
                observation=raw_obs,
                timestep=timestep,
            )
            
            # è®¾ç½® must_go æ ‡å¿—
            timed_obs.must_go = True
            
            # åºåˆ—åŒ–å¹¶å‘é€
            obs_bytes = pickle.dumps(timed_obs)
            observation_iterator = send_bytes_in_chunks(
                obs_bytes,
                services_pb2.Observation,
                log_prefix="[CLIENT] Observation",
                silent=True,
            )
            self.stub.SendObservations(observation_iterator)
            
            # æ¸…é™¤ must_go æ ‡å¿—ï¼ˆå°†åœ¨æ”¶åˆ°åŠ¨ä½œåé‡æ–°è®¾ç½®ï¼‰
            self.must_go.clear()
            
            logger.debug(f"Sent observation #{timestep}")
            return True
            
        except grpc.RpcError as e:
            logger.error(f"Error sending observation: {e}")
            return False
    
    def get_action_from_queue(self) -> Optional[np.ndarray]:
        """ä»é˜Ÿåˆ—è·å–åŠ¨ä½œ"""
        try:
            with self.action_queue_lock:
                if self.action_queue.empty():
                    return None
                
                timestep, action = self.action_queue.get_nowait()
                
                with self.latest_action_lock:
                    self.latest_action = timestep
                
                return action
        except Empty:
            return None
    
    def _prepare_obs_buffer(self, dataloader, dataset):
        obs_buffer = deque(maxlen=99)
        iterator = tqdm(enumerate(dataloader), total=dataset.num_frames, desc="Processing")

        for data_step, batch in iterator:
            obs_data = {
                'state': batch['observation.state'],
            }

            camera_names = get_camera_names(CAMERA_COMPONENTS)
            for camera_name in camera_names:
                obs_key = get_camera_observation_key(camera_name, use_image_features=False)
                if obs_key in batch:
                    obs_data[camera_name] = (batch[obs_key][0].cpu().numpy().astype(np.float32) / 255.0).transpose(1, 2, 0)
                else:
                    fallback_key = f"observation.images.{camera_name}"
                    if fallback_key in batch:
                        obs_data[fallback_key] = batch[fallback_key]
                    elif data_step == 0:
                        print(f"[WARN]: Camera observation key '{obs_key}' not found in batch. Available keys: {[k for k in batch.keys() if 'image' in k.lower()]}")

            obs_buffer.append(obs_data)

        return obs_buffer
        
    def run(self):
        """è¿è¡Œå¼‚æ­¥æ¨ç†å¾ªç¯"""
        rospy.loginfo("Starting async inference loop...")
        
        # å¯åŠ¨åŠ¨ä½œæ¥æ”¶çº¿ç¨‹
        action_receiver_thread = threading.Thread(target=self.receive_actions, daemon=True)
        action_receiver_thread.start()
        
        # ç­‰å¾…çº¿ç¨‹å¯åŠ¨
        time.sleep(1)
        self.robot_sdk.control.set_external_control_arm_mode()
        
        # åˆå§‹åŒ–æœºå™¨äººæ§åˆ¶
        if ROBOT_VERSION == "4_pro":
            self.robot_sdk.control.set_direct_to_wbc()
            function_key = "direct_to_wbc"
        elif ROBOT_VERSION == "5_wheel":
            self.robot_sdk.control.set_arm_quick_mode(True)
            function_key = "set_arm_quick_mode"
        
        input(f"å½“å‰æœºå™¨äººæ¨¡å¼ä¸º: {ROBOT_VERSION} | æ§åˆ¶æ¨¡å¼ {function_key} ç»“æŸ, æŒ‰å›è½¦ç»§ç»­ ==== \n")
        time.sleep(1.0)
        
        # åˆå§‹åŒ–æ‰‹è‡‚ä½ç½®
        self.robot_sdk.control.control_arm_joint_positions([
            -0.13108279410748547, 0.8129094913924698, -0.24350018506614143, -2.417029590409915, 1.3373353902132268, 0.40744714341534344, 0.9697406158372316,
            -0.13080062822719687, -0.8167237074915805, 0.2473180179648636, -2.410544954816824, -1.3350419244819163,-0.40477685656131995, 0.9716470019773075
        ])

        input(f"è½¨è¿¹å›æ”¾ç»“æŸ, æŒ‰å›è½¦ç»§ç»­ ==== \n")
        rospy.loginfo("=" * 80)
        rospy.loginfo("ğŸš€ Starting async inference control loop...")
        rospy.loginfo(f"   Server address: {self.server_address}")
        rospy.loginfo(f"   Control frequency: {self.fps} Hz (dt={self.environment_dt:.4f}s)")
        rospy.loginfo(f"   Action chunk size: {self.action_chunk_size}")
        rospy.loginfo(f"   Task: {self.task_description}")
        rospy.loginfo(f"   Control arm: {self.control_arm}, Control claw: {self.control_claw}")
        rospy.loginfo("=" * 80)
        time.sleep(1.0)
        
        # ç”¨äºåŠ¨ä½œé‡é‡‡æ ·å’Œä½é€šæ»¤æ³¢
        resampled_action_queue: deque = deque()
        last_executed_action: Optional[np.ndarray] = None
        
        step_counter = 0
        last_status_log_time = time.time()
        status_log_interval = 2.0  # æ¯2ç§’æ‰“å°ä¸€æ¬¡çŠ¶æ€ä¿¡æ¯
        last_obs_sent_time = 0
        last_chunk_received_time = 0
        
        # ---------------------------------------------------------------

        dataset = LeRobotDataset(repo_id=0, root=self.lerobot_dataset_path, episodes=[0])
        ep_meta = dataset.meta.episodes[0]
        ep_start = ep_meta["dataset_from_index"]
        ep_end = ep_meta["dataset_to_index"]
        dataset.hf_dataset = dataset.hf_dataset.select(range(ep_start, ep_end))
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=0,
            batch_size=1,
            shuffle=False,
            pin_memory=True,
            drop_last=False,
        )
        first_batch = next(iter(dataloader))
        action_dim = first_batch['action'].shape[1]
        obs_dim = first_batch['observation.state'].shape[1]
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=0,
            batch_size=1,
            shuffle=False,
            pin_memory=True,
            drop_last=False,
        )

        obs_buffer = self._prepare_obs_buffer(dataloader, dataset)
        # ---------------------------------------------------------------

        # æ£€æŸ¥åŠ¨ä½œæ¥æ”¶çº¿ç¨‹çŠ¶æ€
        with self.action_queue_lock:
            initial_queue_size = self.action_queue.qsize()
        rospy.loginfo(f"[CLIENT] Action receiver thread status: Running | Initial queue size: {initial_queue_size}")
        
        try:
            rospy.loginfo("[CLIENT] Entering main control loop...")
            loop_iteration = 0
            while not self.shutdown_event.is_set():
                loop_iteration += 1
                
                # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
                if loop_iteration == 1:
                    rospy.loginfo("[CLIENT] First loop iteration started")
                    with self.action_queue_lock:
                        queue_size = self.action_queue.qsize()
                    with self.latest_action_lock:
                        latest_timestep = self.latest_action
                    rospy.loginfo(
                        f"[CLIENT] Initial state | Queue size: {queue_size} | "
                        f"Latest timestep: {latest_timestep} | "
                        f"Must go: {self.must_go.is_set()}"
                    )
                
                # # 1. è·å–è§‚æµ‹(online mode)
                # obs_data, camera_obs, camera_obs_ts, robot_obs, robot_obs_ts = self.env.get_obs()

                # 2. å‘é€è§‚æµ‹
                obs_sent = self.send_observation(obs_buffer, resampled_action_queue)
                if obs_sent:
                    last_obs_sent_time = time.time()
                    with self.latest_action_lock:
                        rospy.loginfo(
                            f"[CLIENT] Observation sent | Timestep: {self.latest_action} | "
                            f"Queue size: {self.action_queue.qsize()} | "
                            f"Resampled queue: {len(resampled_action_queue)}"
                        )
                
                # 3. è·å–åŠ¨ä½œï¼ˆä»é˜Ÿåˆ—æˆ–é‡é‡‡æ ·é˜Ÿåˆ—ï¼‰
                current_action = None
            
                # if len(resampled_action_queue) == 0:
                if (len(resampled_action_queue) < 75):
                    # ä»æœåŠ¡å™¨åŠ¨ä½œé˜Ÿåˆ—è·å–æ–°åŠ¨ä½œå—
                    action_chunk = []
                    with self.action_queue_lock:
                        server_queue_size = self.action_queue.qsize()
                    
                    while len(action_chunk) < self.action_chunk_size / 2:
                        action = self.get_action_from_queue()
                        if action is None:
                            break
                        action_chunk.append(action)
                    
                    if len(action_chunk) > 0:
                        last_chunk_received_time = time.time()
                        rospy.loginfo(
                            f"[CLIENT] Action chunk received | Size: {len(action_chunk)} | "
                            f"Server queue (before): {server_queue_size} | "
                            f"Server queue (after): {self.action_queue.qsize()}"
                        )
                        # è½¬æ¢ä¸º numpy array
                        action_chunk = np.array(action_chunk)  # (chunk_size, action_dim)
                        
                        # é‡é‡‡æ ·åˆ°æ§åˆ¶é¢‘ç‡
                        action_dim = action_chunk.shape[1]
                        if action_dim == 16:
                            arm_dims = slice(0, 14)
                            claw_dims = slice(14, 16)
                        elif action_dim == 18:
                            arm_dims = slice(0, 14)
                            claw_dims = slice(14, 16)
                        else:
                            arm_dims = slice(0, 14)
                            claw_dims = slice(14, min(16, action_dim))
                        
                        resampled_chunk = resample_chunk_with_claw_hold(
                            action_chunk,
                            previous_action=last_executed_action,
                            control_frequency=self.env.control_frequency,
                            source_dt=MODEL_ACTION_DT,
                            arm_dims=arm_dims,
                            claw_dims=claw_dims
                        )
                        
                        # åº”ç”¨ä½é€šæ»¤æ³¢
                        if ENABLE_CHUNK_TRANSITION_LOWPASS and last_executed_action is not None:
                            transition_steps = max(
                                1,
                                int(round(self.env.control_frequency * CHUNK_TRANSITION_DURATION_S))
                            )
                            resampled_chunk = apply_lowpass_transition(
                                resampled_chunk,
                                previous_action=last_executed_action,
                                alpha=LOWPASS_ALPHA,
                                transition_steps=transition_steps,
                                smooth_slice=arm_dims
                            )
                        
                        # æ·»åŠ åˆ°é‡é‡‡æ ·é˜Ÿåˆ—
                        if len(resampled_action_queue) != 0:
                            resampled_action_queue.clear()
                        resampled_action_queue.extend(resampled_chunk)
                        rospy.loginfo(
                            f"[CLIENT] Action chunk resampled | "
                            f"Original: {len(action_chunk)} | "
                            f"Resampled: {len(resampled_chunk)} | "
                            f"Resampled queue size: {len(resampled_action_queue)}"
                        )
            
                # 4. ä»é‡é‡‡æ ·é˜Ÿåˆ—è·å–å½“å‰åŠ¨ä½œ
                # if len(resampled_action_queue) > 0:
                if len(resampled_action_queue) > 0:
                    current_action = resampled_action_queue.popleft()
                else:
                    continue
            
                # 5. æ‰§è¡ŒåŠ¨ä½œ
                if current_action is not None:
                    control_cmd_pose = ("Cmd_pose_z" in ACTION_COMPONENTS or "Cmd_pose_pitch" in ACTION_COMPONENTS)
                    self.env.exec_actions(
                        actions=current_action,
                        control_arm=self.control_arm,
                        control_claw=self.control_claw,
                        control_cmd_pose=control_cmd_pose
                    )
                    last_executed_action = current_action.copy()
                    step_counter += 1
                else:
                    # å¦‚æœæ²¡æœ‰åŠ¨ä½œå¯æ‰§è¡Œï¼Œè®°å½•è­¦å‘Š
                    if step_counter % 100 == 0:  # æ¯100æ­¥æ‰“å°ä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                        logger.warning(
                            f"[CLIENT] No action available | "
                            f"Server queue: {self.action_queue.qsize()} | "
                            f"Resampled queue: {len(resampled_action_queue)}"
                        )
            
                # 6. å®šæœŸæ‰“å°çŠ¶æ€ä¿¡æ¯
                current_time = time.time()
                if current_time - last_status_log_time >= status_log_interval:
                    with self.action_queue_lock:
                        server_queue_size = self.action_queue.qsize()
                    with self.latest_action_lock:
                        latest_timestep = self.latest_action
                    
                    time_since_last_obs = current_time - last_obs_sent_time if last_obs_sent_time > 0 else 0
                    time_since_last_chunk = current_time - last_chunk_received_time if last_chunk_received_time > 0 else 0
                    
                    rospy.loginfo(
                        f"[CLIENT] Status Summary | "
                        f"Steps: {step_counter} | "
                        f"Latest timestep: {latest_timestep} | "
                        f"Server queue: {server_queue_size}/{self.action_chunk_size_received} | "
                        f"Resampled queue: {len(resampled_action_queue)} | "
                        f"Time since last obs: {time_since_last_obs:.2f}s | "
                        f"Time since last chunk: {time_since_last_chunk:.2f}s"
                    )
                    last_status_log_time = current_time

            self.shutdown_event.set()
                
        except KeyboardInterrupt:
            rospy.loginfo("Interrupted by user")
        finally:
            self.shutdown_event.set()
            self.channel.close()
            rospy.loginfo("Async client stopped")


def main():
    parser = argparse.ArgumentParser(description='GROOT Async Inference Client for Depalletize Task')
    parser.add_argument('--server_address', type=str, default='127.0.0.1:8080',
                        help='gRPC server address (host:port)')
    parser.add_argument('--ckpt_path', type=str, required=True,
                        help='Path to GROOT checkpoint')
    parser.add_argument('--action_chunk_size', type=int, default=20,
                        help='Action chunk size')
    parser.add_argument('--lerobot_dataset_path', type=str, default=None,
                        help='Path to LeRobot dataset (for statistics)')
    parser.add_argument('--task_description', type=str, default='Depalletize the box',
                        help='Task description')
    parser.add_argument('--fps', type=float, default=30.0,
                        help='Control frequency (FPS)')
    parser.add_argument('--chunk_size_threshold', type=float, default=0.5,
                        help='Threshold for sending new observations (queue_size/chunk_size < threshold)')
    parser.add_argument('--rotate-head-camera', action='store_true',
                        help='If set, rotate head camera images (image) by 180 degrees.')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ– ROS èŠ‚ç‚¹
    if not rospy.get_node_uri():
        rospy.init_node('groot_async_client', anonymous=True)
    
    # åˆ›å»ºå®¢æˆ·ç«¯å¹¶è¿è¡Œ
    client = GrootAsyncClient(
        server_address=args.server_address,
        ckpt_path=args.ckpt_path,
        action_chunk_size=args.action_chunk_size,
        lerobot_dataset_path=args.lerobot_dataset_path,
        task_description=args.task_description,
        fps=args.fps,
        chunk_size_threshold=args.chunk_size_threshold,
        rotate_head_camera=args.rotate_head_camera,
    )
    
    client.run()


if __name__ == '__main__':
    main()